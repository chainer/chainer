# Multi-Layer Perceptron for MNIST Classification with static subgraph optimization

This is a minimal example to write a feed-forward net.
The code consists of three parts: dataset preparation, network and optimizer definition, and learning loop.
This is a common routine to write a learning process of networks with dataset that is small enough to fit into memory.

If you want to run this example on the N-th GPU, pass `--gpu=N` to the script.

## Requirements

- matplotlib
